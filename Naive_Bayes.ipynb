{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Naive Bayes Classifier\n",
    "### Mobin Roohi\n",
    "### SID: 610300060"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will implement a Naive Bayes classifier from the ground up and compare it with the Sci-kit implementation using two datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) What is Naive Bayes?\n",
    "The optimal Bayes classifier works by using the bayes rule and class-conditional probability distributions available. \n",
    "$$P(\\omega_i|\\mathbf{x}) = \\frac{P(\\omega_i)p(\\mathbf{x}|\\omega_i)}{p(\\mathbf{x})},$$\n",
    "\n",
    "Following this, the discriminant function for the classifier becomes,\n",
    "$$g_i(\\mathbf{x}) = P(\\omega_i)p(\\mathbf{x}|\\omega_i).$$\n",
    "Using this discrimnant function, the Bayes classifier produces optimal results in terms of probability of classification error. However, there are two issues associated with the Bayes classifier that prevents it from being a practical classifier and mostly making it a theoretical and optimal benchmark to strive for. These issue are:\n",
    "\n",
    "1. There is an assumption that we know the class-conditional (likelihood) probability distributions and that they are available to us. In reality, this is usually not the case and these distributions need to be estimated, which may produce suboptimal results. There is also the case that estimating these distribution maybe too complex and challenging.\n",
    "\n",
    "2. The estimation of these joint distributions, which are needed for the classifier, is computationally expensive.\n",
    "\n",
    "Assuming that we can estimate the joint distributions, and that it is possible, the remaining issue is the second one mentioned. To fix this, we can make a \"naive\" assumption that there is conditional independence between every pair of features given the value of the class variable.\n",
    "Thus we can rewrite the result of the Bayes theorem as:\n",
    "$$P(\\omega_i|\\mathbf{x}) = \\frac{P(\\omega_i)p(\\mathbf{x}|\\omega_i)}{p(\\mathbf{x})} = \\frac{P(\\omega_i)\\prod_{j=1}^n p(x_j|\\omega_i)}{p(\\mathbf{x})}$$\n",
    "where $\\mathbf{x} = [x_1, x_2, \\dots, x_n]^T$.\n",
    "\n",
    "We can rewrite this as the following discriminant function,\n",
    "$$g_i(\\mathbf{x})={P(\\omega_i)\\prod_{j=1}^n p(x_j|\\omega_i)}$$\n",
    "This is the discriminant function for the ***Naive Bayes classifier***. So it is the Bayes classifier with the assumption of conditional independence. \n",
    "\n",
    "Naive Bayes classifiers can be fast compared to more complex methods. The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one dimensional distribution. This helps solve issues that are cause by the curse of dimensionality.\n",
    "\n",
    "Although, the assumption of conditional independence makes the task less computationally expensive, it is clear that it may lead to more classification error, since the assumption may not be true. Despite this and it simplicity, Naive Bayes classifier has shown to work well in a wide range of application, such as text specific applications like email spam detection.\n",
    "\n",
    "Despite them being rare, independent data and features, could be a good indicator that this classifier will perform well. Naive Bayes also works well in high-dimensional spaces, such as text classification, where the dimensionality of the data (e.g., the number of unique words in the dataset) is very high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Implementation From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will familiarize ourselves with the dataset that we will be working with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"./data/survey lung cancer.csv\"\n",
    "\n",
    "df = pd.read_csv(data, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 16)"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions (data_num, feature_num)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SMOKING</th>\n",
       "      <th>YELLOW_FINGERS</th>\n",
       "      <th>ANXIETY</th>\n",
       "      <th>PEER_PRESSURE</th>\n",
       "      <th>CHRONIC DISEASE</th>\n",
       "      <th>FATIGUE</th>\n",
       "      <th>ALLERGY</th>\n",
       "      <th>WHEEZING</th>\n",
       "      <th>ALCOHOL CONSUMING</th>\n",
       "      <th>COUGHING</th>\n",
       "      <th>SHORTNESS OF BREATH</th>\n",
       "      <th>SWALLOWING DIFFICULTY</th>\n",
       "      <th>CHEST PAIN</th>\n",
       "      <th>LUNG_CANCER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  GENDER AGE SMOKING  YELLOW_FINGERS  ANXIETY PEER_PRESSURE CHRONIC DISEASE  \\\n",
       "0      M  69       1               2        2             1               1   \n",
       "1      M  74       2               1        1             1               2   \n",
       "2      F  59       1               1        1             2               1   \n",
       "3      M  63       2               2        2             1               1   \n",
       "4      F  63       1               2        1             1               1   \n",
       "\n",
       "  FATIGUE  ALLERGY  WHEEZING ALCOHOL CONSUMING COUGHING SHORTNESS OF BREATH  \\\n",
       "0        2        1        2                 2        2                   2   \n",
       "1        2        2        1                 1        1                   2   \n",
       "2        2        1        2                 1        2                   2   \n",
       "3        1        1        1                 2        1                   1   \n",
       "4        1        1        2                 1        2                   2   \n",
       "\n",
       "  SWALLOWING DIFFICULTY  CHEST PAIN LUNG_CANCER  \n",
       "0                     2           2         YES  \n",
       "1                     2           2         YES  \n",
       "2                     1           2          NO  \n",
       "3                     2           2          NO  \n",
       "4                     1           1          NO  "
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 309 entries, 0 to 308\n",
      "Data columns (total 16 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   GENDER                 309 non-null    object\n",
      " 1   AGE                    309 non-null    object\n",
      " 2   SMOKING                309 non-null    object\n",
      " 3   YELLOW_FINGERS         309 non-null    int64 \n",
      " 4   ANXIETY                309 non-null    int64 \n",
      " 5   PEER_PRESSURE          309 non-null    object\n",
      " 6   CHRONIC DISEASE        309 non-null    object\n",
      " 7   FATIGUE                309 non-null    object\n",
      " 8   ALLERGY                309 non-null    object\n",
      " 9   WHEEZING               309 non-null    object\n",
      " 10  ALCOHOL CONSUMING      309 non-null    object\n",
      " 11  COUGHING               309 non-null    object\n",
      " 12  SHORTNESS OF BREATH    309 non-null    object\n",
      " 13  SWALLOWING DIFFICULTY  309 non-null    object\n",
      " 14  CHEST PAIN             309 non-null    int64 \n",
      " 15  LUNG_CANCER            309 non-null    object\n",
      "dtypes: int64(3), object(13)\n",
      "memory usage: 38.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Preprocess the Data\n",
    "Convert the categorical data into numerical values and remove missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['M', '69', '1', 2, 2, '1', '1', '2', '1', '2', '2', '2', '2',\n",
       "        '2', 2, 'YES'],\n",
       "       ['M', '74', '2', 1, 1, '1', '2', '2', '2', '1', '1', '1', '2',\n",
       "        '2', 2, 'YES'],\n",
       "       ['F', '59', '1', 1, 1, '2', '1', '2', '1', '2', '1', '2', '2',\n",
       "        '1', 2, 'NO'],\n",
       "       ['M', '63', '2', 2, 2, '1', '1', '1', '1', '1', '2', '1', '1',\n",
       "        '2', 2, 'NO'],\n",
       "       ['F', '63', '1', 2, 1, '1', '1', '1', '1', '2', '1', '2', '2',\n",
       "        '1', 1, 'NO']], dtype=object)"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = df.values\n",
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.values\n",
    "train_data[train_data == \"YES\"] = \"2\"\n",
    "train_data[train_data == \"NO\"] = \"1\"\n",
    "train_data[train_data == \"M\"] = \"1\"\n",
    "train_data[train_data == \"F\"] = \"2\"\n",
    "mask = (train_data == 'x')\n",
    "rows_with_x = np.any(mask, axis=1)\n",
    "train_data = train_data[~rows_with_x]\n",
    "train_data[:5]\n",
    "train_data = train_data.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Split Data Into Separate Training and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = train_data[:, 0:train_data.shape[1] - 1]\n",
    "y_data = train_data[:, -1]\n",
    "train_size = int(0.8 * x_data.shape[0])\n",
    "indices = np.arange(x_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:]\n",
    "x_train = x_data[train_indices]\n",
    "y_train = y_data[train_indices]\n",
    "x_test = x_data[test_indices]\n",
    "y_test = y_data[test_indices]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Implement the Naive Bayes\n",
    "Here we implement the Naive Bayes classifier, using multinomial NB for the categorical features and Gaussian NB for the continuous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive_Bayes:\n",
    "    def __init__(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.means = {}\n",
    "        self.vars = {}\n",
    "        self.priors = {}\n",
    "        self.class_counts = {} \n",
    "        self.feature_counts = {} \n",
    "        for class_value in [1, 2]:\n",
    "            indices = np.where(self.y_train == class_value)\n",
    "            self.means[class_value] = np.mean(self.x_train[indices, 1], axis=1)  \n",
    "            self.vars[class_value] = np.var(self.x_train[indices, 1], axis=1)\n",
    "            self.priors[class_value] = len(indices[0]) / float(len(self.y_train))\n",
    "            self.class_counts[class_value] = len(indices[0])\n",
    "            for i in range(self.x_train.shape[1]):\n",
    "                if i != 1: \n",
    "                    feature_values, counts = np.unique(self.x_train[indices, i], return_counts=True)\n",
    "                    self.feature_counts[(class_value, i)] = dict(zip(feature_values, counts))\n",
    "\n",
    "    def gaussian_density(self, class_val, x):\n",
    "        mean = self.means[class_val]\n",
    "        var = self.vars[class_val] + 1e-8\n",
    "        return np.exp(- (x - mean) ** 2 / (2 * var)) / np.sqrt(2 * np.pi * var)\n",
    "\n",
    "    def multinomial_probability(self, class_val, feature_index, feature_value):\n",
    "        if (class_val, feature_index) in self.feature_counts and feature_value in \\\n",
    "            self.feature_counts[(class_val, feature_index)]:\n",
    "            return (self.feature_counts[(class_val, feature_index)][feature_value] + 1) \\\n",
    "                / (self.class_counts[class_val] + len(self.feature_counts[(class_val, feature_index)]))\n",
    "        else:\n",
    "            return 1 / (self.class_counts[class_val] + len(self.feature_counts[(class_val, feature_index)]))\n",
    "\n",
    "    def predict(self, x):\n",
    "        posteriors = []\n",
    "        for class_val in self.priors.keys():\n",
    "            prior = np.log(self.priors[class_val])\n",
    "            conditional_gaussian = np.log(self.gaussian_density(class_val, x[1]))\n",
    "            conditional_multinomial = np.sum([np.log(self.multinomial_probability(class_val, i, x[i])) \\\n",
    "                                              for i in range(len(x)) if i != 1])\n",
    "            posterior = prior + conditional_gaussian + conditional_multinomial\n",
    "            posteriors.append(posterior)\n",
    "        return np.argmax(posteriors) + 1\n",
    "\n",
    "    def get_prediction(self, x_test):\n",
    "        return [self.predict(x) for x in x_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB1 = Naive_Bayes(x_train, y_train)\n",
    "y_train_pred = NB1.get_prediction(x_train)\n",
    "y_pred = NB1.get_prediction(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have implemented the Naive Bayes from scratch without using any libraries, we will now import the Sci-Kit learn library to easily evaluate the model with metrics and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score,\\\n",
    "      recall_score, f1_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9322033898305084\n",
      "Test Precision: 0.6\n",
      "Test Recall: 0.6\n",
      "Test F1 Score: 0.6\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy_test}\")\n",
    "\n",
    "average_type = 'binary' \n",
    "\n",
    "precision_test = precision_score(y_test, y_pred, average=average_type)\n",
    "recall_test = recall_score(y_test, y_pred, average=average_type)\n",
    "f1_test = f1_score(y_test, y_pred, average=average_type)\n",
    "\n",
    "print(f\"Test Precision: {precision_test}\")\n",
    "print(f\"Test Recall: {recall_test}\")\n",
    "print(f\"Test F1 Score: {f1_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 3  2]\n",
      " [ 2 52]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.60      0.60         5\n",
      "           2       0.96      0.96      0.96        54\n",
      "\n",
      "    accuracy                           0.93        59\n",
      "   macro avg       0.78      0.78      0.78        59\n",
      "weighted avg       0.93      0.93      0.93        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Implement Using Sci-Kit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred1 = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9152542372881356\n",
      "Test Precision: 0.5\n",
      "Test Recall: 0.6\n",
      "Test F1 Score: 0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = accuracy_score(y_test, y_pred1)\n",
    "print(f\"Test Accuracy: {accuracy_test}\")\n",
    "\n",
    "average_type = 'binary'\n",
    "\n",
    "precision_test = precision_score(y_test, y_pred1, average=average_type)\n",
    "recall_test = recall_score(y_test, y_pred1, average=average_type)\n",
    "f1_test = f1_score(y_test, y_pred1, average=average_type)\n",
    "\n",
    "print(f\"Test Precision: {precision_test}\")\n",
    "print(f\"Test Recall: {recall_test}\")\n",
    "print(f\"Test F1 Score: {f1_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 3  2]\n",
      " [ 3 51]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred1)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the results, looking at accuracy, precision, recall and F1-score, we can see that our model has similar performance to Sci-Kit Learn's model. Something I found to be interesting was that the error metrics for a lot of runs were the same between the two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lung cancer detection is highly important. That is why we need to look for classifiers that are safe and sure in detecting when there is cancer. Here, looking at the confusion matrices, we can clearly see that the classifier misses the cancer more than we can afford to. Thus for this application, although the accuracy of the classifier is good enough, but we need to look for alternatives that will not miss cancer detection as frequently. Naive Bayes can be used in tasks that are not as critical as cancer detection systems, like the classic example of email spam detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason could be that the features here are highly dependent on one another and this goes against the conditional indpendence assumption of the Naive Bayes classifer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Web Page Phishing Dataset\n",
    "This time, we are using Naive Bayes for a task that we know it is known to do well on. Naive Bayes performs well in detecting text-based fraud/spam. Here, we use it to detect which websites are phishing and which are not, a very similar task in tone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"./data/web-page-phishing.csv\"\n",
    "\n",
    "df = pd.read_csv(data, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100077, 20)"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions (data_num, feature_num)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_length</th>\n",
       "      <th>n_dots</th>\n",
       "      <th>n_hypens</th>\n",
       "      <th>n_underline</th>\n",
       "      <th>n_slash</th>\n",
       "      <th>n_questionmark</th>\n",
       "      <th>n_equal</th>\n",
       "      <th>n_at</th>\n",
       "      <th>n_and</th>\n",
       "      <th>n_exclamation</th>\n",
       "      <th>n_space</th>\n",
       "      <th>n_tilde</th>\n",
       "      <th>n_comma</th>\n",
       "      <th>n_plus</th>\n",
       "      <th>n_asterisk</th>\n",
       "      <th>n_hastag</th>\n",
       "      <th>n_dollar</th>\n",
       "      <th>n_percent</th>\n",
       "      <th>n_redirection</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_length  n_dots  n_hypens  n_underline  n_slash  n_questionmark  \\\n",
       "0          37       3         0            0        0               0   \n",
       "1          77       1         0            0        0               0   \n",
       "2         126       4         1            2        0               1   \n",
       "3          18       2         0            0        0               0   \n",
       "4          55       2         2            0        0               0   \n",
       "\n",
       "   n_equal  n_at  n_and  n_exclamation  n_space  n_tilde  n_comma  n_plus  \\\n",
       "0        0     0      0              0        0        0        0       0   \n",
       "1        0     0      0              0        0        0        0       0   \n",
       "2        3     0      2              0        0        0        0       0   \n",
       "3        0     0      0              0        0        0        0       0   \n",
       "4        0     0      0              0        0        0        0       0   \n",
       "\n",
       "   n_asterisk  n_hastag  n_dollar  n_percent  n_redirection  phishing  \n",
       "0           0         0         0          0              0         0  \n",
       "1           0         0         0          0              1         1  \n",
       "2           0         0         0          0              1         1  \n",
       "3           0         0         0          0              1         0  \n",
       "4           0         0         0          0              1         0  "
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100077 entries, 0 to 100076\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count   Dtype\n",
      "---  ------          --------------   -----\n",
      " 0   url_length      100077 non-null  int64\n",
      " 1   n_dots          100077 non-null  int64\n",
      " 2   n_hypens        100077 non-null  int64\n",
      " 3   n_underline     100077 non-null  int64\n",
      " 4   n_slash         100077 non-null  int64\n",
      " 5   n_questionmark  100077 non-null  int64\n",
      " 6   n_equal         100077 non-null  int64\n",
      " 7   n_at            100077 non-null  int64\n",
      " 8   n_and           100077 non-null  int64\n",
      " 9   n_exclamation   100077 non-null  int64\n",
      " 10  n_space         100077 non-null  int64\n",
      " 11  n_tilde         100077 non-null  int64\n",
      " 12  n_comma         100077 non-null  int64\n",
      " 13  n_plus          100077 non-null  int64\n",
      " 14  n_asterisk      100077 non-null  int64\n",
      " 15  n_hastag        100077 non-null  int64\n",
      " 16  n_dollar        100077 non-null  int64\n",
      " 17  n_percent       100077 non-null  int64\n",
      " 18  n_redirection   100077 non-null  int64\n",
      " 19  phishing        100077 non-null  int64\n",
      "dtypes: int64(20)\n",
      "memory usage: 15.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Split the Training/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = df.values + 1\n",
    "x_data = train_data[:, 0:train_data.shape[1] - 1]\n",
    "y_data = train_data[:, -1]\n",
    "train_size = int(0.8 * x_data.shape[0])\n",
    "indices = np.arange(x_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:]\n",
    "x_train = x_data[train_indices]\n",
    "y_train = y_data[train_indices]\n",
    "x_test = x_data[test_indices]\n",
    "y_test = y_data[test_indices]\n",
    "np.unique(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Implemented from Scratch Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a new naive bayes classifier\n",
    "NB2 = Naive_Bayes(x_train, y_train)\n",
    "y_pred = NB2.get_prediction(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8442745803357314\n",
      "Test Precision: 0.8517757557968888\n",
      "Test Recall: 0.9136560409287682\n",
      "Test F1 Score: 0.8816314130558615\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy_test}\")\n",
    "\n",
    "average_type = 'binary' \n",
    "\n",
    "precision_test = precision_score(y_test, y_pred, average=average_type)\n",
    "recall_test = recall_score(y_test, y_pred, average=average_type)\n",
    "f1_test = f1_score(y_test, y_pred, average=average_type)\n",
    "\n",
    "print(f\"Test Precision: {precision_test}\")\n",
    "print(f\"Test Recall: {recall_test}\")\n",
    "print(f\"Test F1 Score: {f1_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[11608  1097]\n",
      " [ 2020  5291]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Using Sci-Kit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.712330135891287\n",
      "Test Precision: 0.6933912365681199\n",
      "Test Recall: 0.9802439984258166\n",
      "Test F1 Score: 0.8122350485880128\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy_test}\")\n",
    "\n",
    "average_type = 'binary' \n",
    "\n",
    "precision_test = precision_score(y_test, y_pred, average=average_type)\n",
    "recall_test = recall_score(y_test, y_pred, average=average_type)\n",
    "f1_test = f1_score(y_test, y_pred, average=average_type)\n",
    "\n",
    "print(f\"Test Precision: {precision_test}\")\n",
    "print(f\"Test Recall: {recall_test}\")\n",
    "print(f\"Test F1 Score: {f1_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[12555   234]\n",
      " [ 5364  1863]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like our implementation works better than Sci-Kit Learn's model. The reason for this is probably the fact that our implementation is mixture of a little bit of Gaussian Naive Bayes (column 1) and mostly Multinomial Naive Bayes. In this dataset the data is more categorical in a sense and thus the existence of the large multinomial element causes the classifier to have improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8175959232613909\n",
      "Test Precision: 0.8188926458157227\n",
      "Test Recall: 0.9149940968122786\n",
      "Test F1 Score: 0.8642801382848221\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy_test}\")\n",
    "\n",
    "average_type = 'binary' \n",
    "\n",
    "precision_test = precision_score(y_test, y_pred, average=average_type)\n",
    "recall_test = recall_score(y_test, y_pred, average=average_type)\n",
    "f1_test = f1_score(y_test, y_pred, average=average_type)\n",
    "\n",
    "print(f\"Test Precision: {precision_test}\")\n",
    "print(f\"Test Recall: {recall_test}\")\n",
    "print(f\"Test F1 Score: {f1_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[11625  1080]\n",
      " [ 2571  4740]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
